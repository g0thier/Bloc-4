{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/g0thier/Cours_Data/blob/main/Regressions.ipynb\n",
    "import ast\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "# pd.options.display.max_columns = None\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import( load_iris, load_digits, fetch_lfw_people )\n",
    "from sklearn.ensemble import( AdaBoostClassifier, AdaBoostRegressor, ExtraTreesClassifier, \n",
    "                              GradientBoostingClassifier,RandomForestClassifier, StackingClassifier )\n",
    "\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import( KNNImputer, SimpleImputer )\n",
    "from sklearn.preprocessing import( OneHotEncoder, StandardScaler, LabelEncoder )\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import( LogisticRegression, LinearRegression, Ridge, Lasso )\n",
    "from sklearn.model_selection import( cross_val_score, GridSearchCV, StratifiedShuffleSplit, train_test_split )\n",
    "from sklearn.metrics import( accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, \n",
    "                             f1_score, mean_squared_error, r2_score, RocCurveDisplay )\n",
    "                             \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import ( DecisionTreeClassifier, DecisionTreeRegressor )\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from scipy.stats import mode \n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\", category=DeprecationWarning ) # to avoid deprecation warnings\n",
    "\n",
    "# setting Jedha color palette as default\n",
    "pio.templates[\"jedha\"] = go.layout.Template( layout_colorway=[\"#4B9AC7\", \"#4BE8E0\", \"#9DD4F3\", \"#97FBF6\",\n",
    "                                                              \"#2A7FAF\", \"#23B1AB\", \"#0E3449\", \"#015955\"] )\n",
    "pio.templates.default = \"jedha\"\n",
    "pio.renderers.default = \"svg\" # to be replaced by \"iframe\" if working on JUPITER or \"iframe_connected\" or \"notebook\"\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"src/dataset_tokenized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword_database</th>\n",
       "      <th>target_database</th>\n",
       "      <th>0011</th>\n",
       "      <th>001116</th>\n",
       "      <th>0025</th>\n",
       "      <th>005225</th>\n",
       "      <th>010156</th>\n",
       "      <th>010217</th>\n",
       "      <th>0104</th>\n",
       "      <th>010401</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zotar50</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zourryart</th>\n",
       "      <th>zrnf</th>\n",
       "      <th>zss</th>\n",
       "      <th>zumiez</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zxatheti</th>\n",
       "      <th>zzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ablaz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaz</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ablaz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ablaz</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ablaz</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7547</th>\n",
       "      <td>wreck</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7548</th>\n",
       "      <td>wreck</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>wreck</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7550</th>\n",
       "      <td>wreck</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7551</th>\n",
       "      <td>wreck</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7552 rows × 14530 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     keyword_database  target_database  0011  001116  0025  005225  010156  \\\n",
       "0               ablaz                1   0.0     0.0   0.0     0.0     0.0   \n",
       "1               ablaz                0   0.0     0.0   0.0     0.0     0.0   \n",
       "2               ablaz                1   0.0     0.0   0.0     0.0     0.0   \n",
       "3               ablaz                0   0.0     0.0   0.0     0.0     0.0   \n",
       "4               ablaz                0   0.0     0.0   0.0     0.0     0.0   \n",
       "...               ...              ...   ...     ...   ...     ...     ...   \n",
       "7547            wreck                0   0.0     0.0   0.0     0.0     0.0   \n",
       "7548            wreck                0   0.0     0.0   0.0     0.0     0.0   \n",
       "7549            wreck                0   0.0     0.0   0.0     0.0     0.0   \n",
       "7550            wreck                0   0.0     0.0   0.0     0.0     0.0   \n",
       "7551            wreck                0   0.0     0.0   0.0     0.0     0.0   \n",
       "\n",
       "      010217  0104  010401  ...  zoom  zotar50  zouma  zourryart  zrnf  zss  \\\n",
       "0        0.0   0.0     0.0  ...   0.0      0.0    0.0        0.0   0.0  0.0   \n",
       "1        0.0   0.0     0.0  ...   0.0      0.0    0.0        0.0   0.0  0.0   \n",
       "2        0.0   0.0     0.0  ...   0.0      0.0    0.0        0.0   0.0  0.0   \n",
       "3        0.0   0.0     0.0  ...   0.0      0.0    0.0        0.0   0.0  0.0   \n",
       "4        0.0   0.0     0.0  ...   0.0      0.0    0.0        0.0   0.0  0.0   \n",
       "...      ...   ...     ...  ...   ...      ...    ...        ...   ...  ...   \n",
       "7547     0.0   0.0     0.0  ...   0.0      0.0    0.0        0.0   0.0  0.0   \n",
       "7548     0.0   0.0     0.0  ...   0.0      0.0    0.0        0.0   0.0  0.0   \n",
       "7549     0.0   0.0     0.0  ...   0.0      0.0    0.0        0.0   0.0  0.0   \n",
       "7550     0.0   0.0     0.0  ...   0.0      0.0    0.0        0.0   0.0  0.0   \n",
       "7551     0.0   0.0     0.0  ...   0.0      0.0    0.0        0.0   0.0  0.0   \n",
       "\n",
       "      zumiez  zurich  zxatheti  zzzz  \n",
       "0        0.0     0.0       0.0   0.0  \n",
       "1        0.0     0.0       0.0   0.0  \n",
       "2        0.0     0.0       0.0   0.0  \n",
       "3        0.0     0.0       0.0   0.0  \n",
       "4        0.0     0.0       0.0   0.0  \n",
       "...      ...     ...       ...   ...  \n",
       "7547     0.0     0.0       0.0   0.0  \n",
       "7548     0.0     0.0       0.0   0.0  \n",
       "7549     0.0     0.0       0.0   0.0  \n",
       "7550     0.0     0.0       0.0   0.0  \n",
       "7551     0.0     0.0       0.0   0.0  \n",
       "\n",
       "[7552 rows x 14530 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation Variables explicative X et variable Cible/Target Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'target_database'\n",
    "\n",
    "Y = dataset[:][target_name]\n",
    "X = dataset.drop(columns= [target_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation en Entrainement & Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_features : Index(['0011', '001116', '0025', '005225', '010156', '010217', '0104',\n",
      "       '010401', '0106', '0111',\n",
      "       ...\n",
      "       'zoom', 'zotar50', 'zouma', 'zourryart', 'zrnf', 'zss', 'zumiez',\n",
      "       'zurich', 'zxatheti', 'zzzz'],\n",
      "      dtype='object', length=14528)\n",
      "categorical_features : Index(['keyword_database'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline for numeric features\n",
    "numeric_features = X.select_dtypes([np.number]).columns # Automatically detect positions of numeric columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # missing values will be replaced by columns' median\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create pipeline for categorical features\n",
    "categorical_features = X.select_dtypes(\"object\").columns # Automatically detect positions of categorical columns\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train) # Preprocessing influenceur\n",
    "X_test = preprocessor.transform(X_test) # Preprocessing copieur\n",
    "\n",
    "print(f'numeric_features : {numeric_features}')\n",
    "print(f'categorical_features : {categorical_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model\n",
    "### Qualitatif (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression() # Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train) # Training is always done on train set !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model.predict(X_train) # Predictions on training set\n",
    "Y_test_pred = model.predict(X_test) # Prédictions on test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performances evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set :  0.9877503724548916\n",
      "Accuracy on test set :  0.7379219060225016\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set : \", accuracy_score(Y_train, Y_train_pred))\n",
    "print(\"Accuracy on test set : \", accuracy_score(Y_test, Y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
